{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from dotenv import find_dotenv, load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "# Set OpenAI API key\n",
        "openai.api_type = os.getenv(\"api_type\")\n",
        "openai.api_base = os.getenv(\"api_base\")\n",
        "openai.api_version = os.getenv(\"api_version\")\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      },
      "source": [
        "# RCI Chain with ChatModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T4xsy4ND2av"
      },
      "source": [
        "## Multi Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ezZ5D55uD-Qm"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P_Vz09usvqhb"
      },
      "outputs": [],
      "source": [
        "model = AzureChatOpenAI(\n",
        "        deployment_name=\"chatgpt-gpt35-turbo\",\n",
        "        model_name=\"gpt-35-turbo\",\n",
        "        temperature=0.7,\n",
        "        max_tokens=1000\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z6HVNGkvv9-G"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"tell me an intersting fact about {subject}\"\n",
        "    )\n",
        "\n",
        "reverse_prompt = ChatPromptTemplate.from_template(\n",
        "    \"based on this interesting fact which is chunked down from a meta subject:\\n\\n {interesting_fact}\\n\\n Recover what the meta subject is\\n Subject:\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UoeILxMtwS-A"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "cm8y8Ll4wJMH",
        "outputId": "8f647e6e-158d-4eeb-b3f1-793191c07e43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The first laptop computer, called the Grid Compass, was invented in 1982 and was priced at $8,000. It weighed 10 pounds and had a battery life of just 1 hour.'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"subject\": \"Laptop\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jRzytVdiEwX0"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "\n",
        "langchain.debug = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K82XYV2zGnWg"
      },
      "outputs": [],
      "source": [
        "chain1 = prompt | model | StrOutputParser()\n",
        "\n",
        "chain2 = {\"interesting_fact\": chain1} | reverse_prompt | model | StrOutputParser()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jSVepkyWG0rV",
        "outputId": "dc71faa6-79f9-4ce0-c621-9975dafa796d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"Siemens\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": {\n",
            "    \"subject\": \"Siemens\"\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"Siemens\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"Siemens\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"tell me an intersting fact about Siemens\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: tell me an intersting fact about Siemens\"\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:llm:AzureChatOpenAI] [2.72s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 24,\n",
            "      \"prompt_tokens\": 17,\n",
            "      \"total_tokens\": 41\n",
            "    },\n",
            "    \"model_name\": \"gpt-35-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 6:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] [2.73s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] [2.74s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"interesting_fact\": \"Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"interesting_fact\": \"Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"based on this interesting fact which is chunked down from a meta subject:\\n\\n Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\\n\\n Recover what the meta subject is\\n Subject:\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: based on this interesting fact which is chunked down from a meta subject:\\n\\n Siemens was the first company to develop a practical electric generator, which paved the way for the widespread use of electricity.\\n\\n Recover what the meta subject is\\n Subject:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:AzureChatOpenAI] [483ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"History of Electricity\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"History of Electricity\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 3,\n",
            "      \"prompt_tokens\": 55,\n",
            "      \"total_tokens\": 58\n",
            "    },\n",
            "    \"model_name\": \"gpt-35-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"History of Electricity\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [3.22s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"History of Electricity\"\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'History of Electricity'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain2.invoke({\"subject\": \"Siemens\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqDy4FroigDu"
      },
      "source": [
        "# Testing RCI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cUOH6rVBiNOP"
      },
      "outputs": [],
      "source": [
        "langchain.debug = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8PrgOsByPHZT"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Nb1gtx1vhopk"
      },
      "outputs": [],
      "source": [
        "template=\"You are a helpful assistant that imparts wisdom and guides people with accurate answers.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"{question}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z1vbc_tShv3-"
      },
      "outputs": [],
      "source": [
        "chain1 = chat_prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TQxR1btKhv4J"
      },
      "outputs": [],
      "source": [
        "initial_question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Qnczl4rWhv4J",
        "outputId": "6561eb6f-f1f0-417e-e549-8c8cc97189c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Roger had 5 tennis balls and he bought 2 cans of tennis balls, each containing 3 tennis balls. So, he has a total of 5 + (2 x 3) = 11 tennis balls now.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "initial_answer = chain1.invoke({\"question\": initial_question})\n",
        "initial_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dt4wOS1wPDDG"
      },
      "outputs": [],
      "source": [
        "fake_initial_ai_answer = \"\"\"Roger initially has 5 tennis balls. Each can of tennis balls contains 3 tennis balls, and he bought 2 cans, so he has 2 x 3 = 6 additional tennis balls.\n",
        "Therefore, the total number of tennis balls Roger has now is 5 + 4 = 9.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdifZhmeh5fK"
      },
      "source": [
        "## Part 2 - Critique  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Lyn5cvz2gS2l"
      },
      "outputs": [],
      "source": [
        "template=\"You are a helpful assistant that looks at answers and finds what is wrong with them based on the original question given.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"### Question:\\n\\n{question}\\n\\n ###Answer Given:{initial_answer}\\n\\n Review your previous answer and find problems with your answer\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8Ud512H8gS2x"
      },
      "outputs": [],
      "source": [
        "rc_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VSz9eWU6gagJ"
      },
      "outputs": [],
      "source": [
        "chain2 = rc_prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "xyrzdgNbg-u6",
        "outputId": "08055a11-4e0b-4806-f704-8dd451fbe0b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The answer given has a mistake in the calculation. The answer should be 5 + 2 x 3 = 11. Roger initially has 5 tennis balls, and he buys 2 cans of tennis balls, which gives him a total of 2 x 3 = 6 additional tennis balls. Adding the initial 5 tennis balls to the 6 additional tennis balls gives a total of 11 tennis balls.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "constructive_criticism = chain2.invoke({\"question\": initial_question, \"initial_answer\":fake_initial_ai_answer})\n",
        "constructive_criticism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThJCqWYXi5To"
      },
      "source": [
        "## Part 3 - The Improvement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GF9xkoAJjIZr"
      },
      "outputs": [],
      "source": [
        "template=\"You are a helpful assistant that reviews answers and critiques based on the original question given and write a new improved final answer.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"### Question:\\n\\n{question}\\n\\n ###Answer Given:{initial_answer}\\n\\n \\\n",
        "###Constructive Criticism:{constructive_criticism}\\n\\n Based on the problems you found, improve your answer.\\n\\n### Final Answer:\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kUVYEp0pjIZ5"
      },
      "outputs": [],
      "source": [
        "improvement_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IUGNqQg_l0st"
      },
      "outputs": [],
      "source": [
        "chain3 = improvement_prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yUkfpDedl975",
        "outputId": "2c277e29-9d68-4820-d4b4-c87ec3db927d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Roger initially has 5 tennis balls. He buys 2 cans of tennis balls, which gives him a total of 2 x 3 = 6 additional tennis balls. Adding the initial 5 tennis balls to the 6 additional tennis balls gives a total of 11 tennis balls. Therefore, Roger has 11 tennis balls now.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_result = chain3.invoke({\"question\": initial_question,\n",
        "                              \"initial_answer\":fake_initial_ai_answer,\n",
        "                              \"constructive_criticism\": constructive_criticism})\n",
        "\n",
        "final_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQPHAp5emT9K"
      },
      "source": [
        "## Combined Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v7coUHRTrXW5"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QhXNxN1ZmLqL"
      },
      "outputs": [],
      "source": [
        "\n",
        "chain1 = chat_prompt | model | StrOutputParser()\n",
        "\n",
        "critque_chain = {\"question\": itemgetter(\"question\"),\n",
        "                 \"initial_answer\": chain1 } | rc_prompt | model | StrOutputParser()\n",
        "\n",
        "chain3 = {\"question\": itemgetter(\"question\"),\n",
        "          \"initial_answer\": chain1,\n",
        "          \"constructive_criticism\": critque_chain} | improvement_prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JvTj9xb0rLWG",
        "outputId": "806c63ff-69de-4325-d8fc-5167c8ef67ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"I\\'m tired.\"'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain3.invoke({\"question\":\"Write an sms message to say I am tired\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ihFvgx2ksWtG"
      },
      "outputs": [],
      "source": [
        "langchain.debug = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z_FiZIqBstKY",
        "outputId": "97124c46-5fb5-43dd-a1d0-f80ec9aacf6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": {\n",
            "    \"question\": \"Write an sms message to say I am tired\"\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:prompt:ChatPromptTemplate] [3ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are a helpful assistant that imparts wisdom and guides people with accurate answers.\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"Write an sms message to say I am tired\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 6:llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that imparts wisdom and guides people with accurate answers.\\nHuman: Write an sms message to say I am tired\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": {\n",
            "    \"question\": \"Write an sms message to say I am tired\"\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 7:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 7:chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence > 9:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence > 9:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are a helpful assistant that imparts wisdom and guides people with accurate answers.\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"Write an sms message to say I am tired\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence > 10:llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that imparts wisdom and guides people with accurate answers.\\nHuman: Write an sms message to say I am tired\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 6:llm:AzureChatOpenAI] [2.58s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 15,\n",
            "      \"prompt_tokens\": 38,\n",
            "      \"total_tokens\": 53\n",
            "    },\n",
            "    \"model_name\": \"gpt-35-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 7:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 7:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence] [2.59s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence > 10:llm:AzureChatOpenAI] [2.78s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 13,\n",
            "      \"prompt_tokens\": 38,\n",
            "      \"total_tokens\": 51\n",
            "    },\n",
            "    \"model_name\": \"gpt-35-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence > 11:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence > 11:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap > 8:chain:RunnableSequence] [2.78s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 6:chain:RunnableMap] [2.79s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 12:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 12:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are a helpful assistant that looks at answers and finds what is wrong with them based on the original question given.\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"### Question:\\n\\nWrite an sms message to say I am tired\\n\\n ###Answer Given:\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\\n\\n Review your previous answer and find problems with your answer\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 13:llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that looks at answers and finds what is wrong with them based on the original question given.\\nHuman: ### Question:\\n\\nWrite an sms message to say I am tired\\n\\n ###Answer Given:\\\"I'm feeling exhausted and drained, need to take some rest.\\\"\\n\\n Review your previous answer and find problems with your answer\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 13:llm:AzureChatOpenAI] [3.15s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 43,\n",
            "      \"prompt_tokens\": 76,\n",
            "      \"total_tokens\": 119\n",
            "    },\n",
            "    \"model_name\": \"gpt-35-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 14:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence > 14:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 5:chain:RunnableSequence] [5.95s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] [5.97s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\",\n",
            "  \"constructive_criticism\": \"The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\",\n",
            "  \"constructive_criticism\": \"The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 15:prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"SystemMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"You are a helpful assistant that reviews answers and critiques based on the original question given and write a new improved final answer.\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      },\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"### Question:\\n\\nWrite an sms message to say I am tired\\n\\n ###Answer Given:\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\\n\\n ###Constructive Criticism:The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\\n\\n Based on the problems you found, improve your answer.\\n\\n### Final Answer:\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 16:llm:AzureChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that reviews answers and critiques based on the original question given and write a new improved final answer.\\nHuman: ### Question:\\n\\nWrite an sms message to say I am tired\\n\\n ###Answer Given:\\\"I am feeling exhausted and need to rest. Catch up with you later.\\\"\\n\\n ###Constructive Criticism:The answer provided does not follow the format of an SMS message, which is typically shorter and more concise. Additionally, the answer provided includes unnecessary information and is not a direct and clear statement saying \\\"I am tired.\\\"\\n\\n Based on the problems you found, improve your answer.\\n\\n### Final Answer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 16:llm:AzureChatOpenAI] [612ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\\\"I'm tired, need rest. Talk later.\\\"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\\\"I'm tired, need rest. Talk later.\\\"\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 10,\n",
            "      \"prompt_tokens\": 132,\n",
            "      \"total_tokens\": 142\n",
            "    },\n",
            "    \"model_name\": \"gpt-35-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 17:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 17:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\\"I'm tired, need rest. Talk later.\\\"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [6.59s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"\\\"I'm tired, need rest. Talk later.\\\"\"\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\"I\\'m tired, need rest. Talk later.\"'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain3.invoke({\"question\":\"Write an sms message to say I am tired\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCZO8y8gsvcR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
